{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebaa54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nkhozin\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import rouge\n",
    "from ipynb.fs.full.sari import SARIsent\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from tqdm.auto import trange\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pickle \n",
    "from sklearn.utils import shuffle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.tensorflow\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "from mlflow.models.signature import infer_signature\n",
    "import torch\n",
    "import mlflow\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac13ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_special_tokens(model_name):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    special_tokens = {'pad_token':'<|pad|>','sep_token':'<|sep|>'}\n",
    "    num_add_toks = tokenizer.add_special_tokens(special_tokens)\n",
    "    tokenizer.src_lang = 'ru'\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f95fcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20480 2560\n"
     ]
    }
   ],
   "source": [
    "train_small = pd.read_csv('data\\\\train_small.csv', index_col=0)\n",
    "val = pd.read_csv('data\\\\eval.csv', index_col=0)\n",
    "\n",
    "train_pairs = list(zip(train_small.source, train_small.target))\n",
    "eval_pairs = list(zip(val.source, val.target))\n",
    "print(train_small.shape[0], val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c6c30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'sberbank-ai/rugpt3small_based_on_gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "tokenizer = add_special_tokens(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba2244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplificationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_text, target_text = self.data[index]\n",
    "        encoding = self.tokenizer(source_text, truncation=True, max_length=self.max_length, padding='max_length')\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(encoding['input_ids']),\n",
    "            'attention_mask': torch.tensor(encoding['attention_mask']),\n",
    "            'labels': self.tokenizer(target_text, truncation=True, max_length=self.max_length, padding='max_length')['input_ids'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8684548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "train_dataset = SimplificationDataset(train_pairs, tokenizer, max_length)\n",
    "eval_dataset = SimplificationDataset(eval_pairs, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f09ddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 1000\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=10,\n",
    "    evaluation_strategy='steps',\n",
    "    save_steps=10000,\n",
    "    logging_steps=1000,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=2e-5\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53663115",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"ru_gpt3\"\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n",
    "current_experiment = dict(mlflow.get_experiment_by_name(experiment_name))\n",
    "exp_id = current_experiment['experiment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca69303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/27 14:04:39 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "C:\\Users\\nkhozin\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20480\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6144\n",
      "  Number of trainable parameters = 125231616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6144' max='6144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6144/6144 36:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.615400</td>\n",
       "      <td>0.365979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.357430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.355898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>0.355511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>0.354441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2560\n",
      "  Batch size = 10\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2560\n",
      "  Batch size = 10\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2560\n",
      "  Batch size = 10\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2560\n",
      "  Batch size = 10\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2560\n",
      "  Batch size = 10\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2560\n",
      "  Batch size = 10\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2560\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [256/256 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./rugpt3\n",
      "Configuration saved in ./rugpt3\\config.json\n",
      "Model weights saved in ./rugpt3\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=exp_id):\n",
    "    # Логируем параметры\n",
    "    mlflow.log_param('model_name', model_name)\n",
    "    #mlflow.log_param('max_length', max_length)\n",
    "    mlflow.log_param('train_data_size', len(train_dataset))\n",
    "    mlflow.log_param('batch_size', training_args.per_device_train_batch_size)\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Логируем метрики\n",
    "    metrics = trainer.evaluate()\n",
    "    for key, value in metrics.items():\n",
    "        mlflow.log_metric(key, value)\n",
    "\n",
    "    # Сохраняем модель и логируем путь к ней\n",
    "    output_dir = './rugpt3'\n",
    "    trainer.save_model(output_dir)\n",
    "    mlflow.log_artifacts(output_dir, artifact_path='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a610a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
