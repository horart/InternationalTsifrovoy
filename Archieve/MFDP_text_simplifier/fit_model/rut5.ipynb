{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63f12c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nkhozin\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import mlflow\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import rouge\n",
    "from ipynb.fs.full.sari import SARIsent\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from tqdm.auto import trange\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pickle \n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.tensorflow\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdbac4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self, batch_size, epochs, lr, weight_decay, warmup_steps, num_layers, dropout_rate):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca826093",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('data\\\\eval.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24cb86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pairs = list(zip(val.source, val.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27bd5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = pd.read_csv('data\\\\train_small_medium_mix_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aad20409",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_pairs = list(zip(train_clean.source, train_clean.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b19d9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data\\\\train.csv', index_col=0)\n",
    "train_small = pd.read_csv('data\\\\train_small.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03728eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ext = train[(train['type']!='para_phraser')&(train['size'].isin(['small','medium']))]\n",
    "train_ext_pairs = list(zip(train_ext.source, train_ext.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2792897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small_pairs = list(zip(train_small.source, train_small.target))\n",
    "\n",
    "train_ru_adapt = train[(train['size']=='small')&(train['type']=='ru_adapt')]\n",
    "train_ru_adapt_pairs = list(zip(train_ru_adapt.source, train_ru_adapt.target))\n",
    "\n",
    "train_ru_xlsum = train[(train['size']=='small')&(train['type']=='ru_xlsum')]\n",
    "train_ru_xlsum_pairs = list(zip(train_ru_xlsum.source, train_ru_xlsum.target))\n",
    "\n",
    "train_medium = train[(train['size']=='medium')]\n",
    "train_medium_pairs = list(zip(train_medium.source, train_medium.target))\n",
    "\n",
    "train_large = train[(train['size']=='large')]\n",
    "train_large_pairs = list(zip(train_large.source, train_large.target))\n",
    "\n",
    "train_para_phraser = train[(train['type']=='para_phraser')&(train['size']=='small')]\n",
    "train_para_phraser_pairs = list(zip(train_para_phraser.source, train_para_phraser.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1e2bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_small_pairs:  20480\n",
      "train_ru_xlsum_pairs:  11399\n",
      "train_ru_adapt_pairs:  34500\n",
      "train_medium_pairs:  21803\n",
      "train_large_pairs:  46872\n",
      "train_para_phraser_pairs:  709371\n",
      "eval_pairs:  2560\n"
     ]
    }
   ],
   "source": [
    "print('train_small_pairs: ',len(train_small_pairs))\n",
    "print('train_ru_xlsum_pairs: ',len(train_ru_xlsum_pairs))\n",
    "print('train_ru_adapt_pairs: ',len(train_ru_adapt_pairs))\n",
    "print('train_medium_pairs: ',len(train_medium_pairs))\n",
    "print('train_large_pairs: ',len(train_large_pairs))\n",
    "print('train_para_phraser_pairs: ',len(train_para_phraser_pairs))\n",
    "print('eval_pairs: ',len(eval_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a7d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"rut5_multitask\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "current_experiment = dict(mlflow.get_experiment_by_name(experiment_name))\n",
    "exp_id = current_experiment['experiment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bdd75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model_name, train_pairs, eval_pairs, args, run_name, save_dir, exp_id):\n",
    "    with mlflow.start_run(experiment_id=exp_id, run_name=run_name):\n",
    "        model_name = model_name\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_name, num_layers=args.num_layers, dropout_rate=args.dropout_rate).cuda()\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Определение оптимизатора и планировщика\n",
    "        optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=len(train_pairs) * args.epochs)\n",
    "\n",
    "        for key, value in vars(args).items():\n",
    "            mlflow.log_param(key, value)\n",
    "        model.train()\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        for epoch in range(args.epochs):\n",
    "            random.shuffle(train_pairs)\n",
    "            train_loss = 0\n",
    "            for i in trange(0, int(len(train_pairs) / args.batch_size)):\n",
    "                # игнорирование батчей, для которых не хватает памяти\n",
    "                try:\n",
    "                    batch = train_pairs[i * args.batch_size: (i + 1) * args.batch_size]\n",
    "                    # кодируем\n",
    "                    x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "                    y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "                    # -100 - специальное значение, позволяющее не учитывать токены\n",
    "                    y.input_ids[y.input_ids == 0] = -100  \n",
    "                except OutOfMemoryError:\n",
    "                    print('Ignoring batch due to CUDA out of memory')\n",
    "                    continue\n",
    "                optimizer.zero_grad()\n",
    "                # вычисляем функцию потерь\n",
    "                loss = model(\n",
    "                        input_ids=x.input_ids,\n",
    "                        attention_mask=x.attention_mask,\n",
    "                        labels=y.input_ids,\n",
    "                        decoder_attention_mask=y.attention_mask,\n",
    "                        return_dict=True\n",
    "                    ).loss\n",
    "                train_loss += loss.data.item()\n",
    "                # делаем шаг градиентного спуска\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            train_loss /= int(len(train_pairs) / args.batch_size)\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, epoch)\n",
    "            print(f'Epoch {epoch}, train_loss: {train_loss}')\n",
    "\n",
    "            # вычисление лосса на валидационном датасете\n",
    "            eval_loss = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for j in trange(0, int(len(eval_pairs) / args.batch_size)):\n",
    "                    batch = eval_pairs[j * args.batch_size: (j + 1) * args.batch_size]\n",
    "                    x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "                    y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "                    # -100 - специальное значение, позволяющее не учитывать токены\n",
    "                    loss = model(\n",
    "                        input_ids=x.input_ids,\n",
    "                        attention_mask=x.attention_mask,\n",
    "                        labels=y.input_ids,\n",
    "                        decoder_attention_mask=y.attention_mask,\n",
    "                        return_dict=True\n",
    "                        ).loss\n",
    "                    eval_loss += loss.data.item()\n",
    "\n",
    "            eval_loss /= int(len(eval_pairs) / args.batch_size)\n",
    "            mlflow.log_metric(\"eval_loss\", eval_loss, epoch)\n",
    "            print(f'Epoch {epoch}, eval_loss: {eval_loss}')\n",
    "\n",
    "    model.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757f1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_base(model_name, train_pairs, eval_pairs, args, run_name, save_dir, exp_id):\n",
    "    with mlflow.start_run(experiment_id=exp_id, run_name=run_name):\n",
    "        model_name = model_name\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_name).cuda()\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Определение оптимизатора и планировщика\n",
    "        optimizer = AdamW(model.parameters(), lr=args.lr)\n",
    "        for key, value in vars(args).items():\n",
    "            mlflow.log_param(key, value)\n",
    "        model.train()\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        for epoch in range(args.epochs):\n",
    "            random.shuffle(train_pairs)\n",
    "            train_loss = 0\n",
    "            for i in trange(0, int(len(train_pairs) / args.batch_size)):\n",
    "                # игнорирование батчей, для которых не хватает памяти\n",
    "                try:\n",
    "                    batch = train_pairs[i * args.batch_size: (i + 1) * args.batch_size]\n",
    "                    # кодируем\n",
    "                    x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "                    y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "                    # -100 - специальное значение, позволяющее не учитывать токены\n",
    "                    y.input_ids[y.input_ids == 0] = -100  \n",
    "                except OutOfMemoryError:\n",
    "                    print('Ignoring batch due to CUDA out of memory')\n",
    "                    continue\n",
    "                optimizer.zero_grad()\n",
    "                # вычисляем функцию потерь\n",
    "                loss = model(\n",
    "                        input_ids=x.input_ids,\n",
    "                        attention_mask=x.attention_mask,\n",
    "                        labels=y.input_ids,\n",
    "                        decoder_attention_mask=y.attention_mask,\n",
    "                        return_dict=True\n",
    "                    ).loss\n",
    "                train_loss += loss.data.item()\n",
    "                # делаем шаг градиентного спуска\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            train_loss /= int(len(train_pairs) / args.batch_size)\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, epoch)\n",
    "            print(f'Epoch {epoch}, train_loss: {train_loss}')\n",
    "\n",
    "            # вычисление лосса на валидационном датасете\n",
    "            eval_loss = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for j in trange(0, int(len(eval_pairs) / args.batch_size)):\n",
    "                    batch = eval_pairs[j * args.batch_size: (j + 1) * args.batch_size]\n",
    "                    x = tokenizer([p[0] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "                    y = tokenizer([p[1] for p in batch], return_tensors='pt', padding=True).to(model.device)\n",
    "                    # -100 - специальное значение, позволяющее не учитывать токены\n",
    "                    loss = model(\n",
    "                        input_ids=x.input_ids,\n",
    "                        attention_mask=x.attention_mask,\n",
    "                        labels=y.input_ids,\n",
    "                        decoder_attention_mask=y.attention_mask,\n",
    "                        return_dict=True\n",
    "                        ).loss\n",
    "                    eval_loss += loss.data.item()\n",
    "\n",
    "            eval_loss /= int(len(eval_pairs) / args.batch_size)\n",
    "            mlflow.log_metric(\"eval_loss\", eval_loss, epoch)\n",
    "            print(f'Epoch {epoch}, eval_loss: {eval_loss}')\n",
    "\n",
    "    model.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9442d57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nkhozin\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 3413/3413 [15:54<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 2.144387740876505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, eval_loss: 0.8774029926305086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3413/3413 [15:03<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 1.4094865135684798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, eval_loss: 0.7768663223745398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3413/3413 [15:04<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss: 1.1132303289228649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, eval_loss: 0.8085872846974733\n"
     ]
    }
   ],
   "source": [
    "args = Params(6, 3, 5.74e-5, 0.238, 986, 12, 0.1)\n",
    "train_and_eval('cointegrated/rut5-base-multitask', train_small_pairs, eval_pairs, args, 'train_small', 'rut5_v1', exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73475044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5750/5750 [24:20<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9401020715482857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, eval_loss: 2.557431572479821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5750/5750 [23:24<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 0.5530573506990205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, eval_loss: 2.790240503532786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5750/5750 [23:21<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss: 0.34173941811295633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, eval_loss: 5.449280455078878\n"
     ]
    }
   ],
   "source": [
    "args = Params(6, 3, 5.74e-5, 0.238, 986, 12, 0.1)\n",
    "train_and_eval('rut5_v1', train_ru_adapt_pairs, eval_pairs, args, 'ru_adapt_small', 'rut5_v2', exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5012d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1899/1899 [10:10<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 2.8150222728979344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, eval_loss: 3.9966215807507295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1899/1899 [09:32<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 1.8087356012704938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, eval_loss: 4.502897160993496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1899/1899 [09:32<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss: 1.4528961252262242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:17<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, eval_loss: 4.571879478127744\n"
     ]
    }
   ],
   "source": [
    "args = Params(6, 3, 5.74e-5, 0.238, 986, 12, 0.1)\n",
    "train_and_eval('rut5_v2', train_ru_xlsum_pairs, eval_pairs, args, 'ru_xlsum_small', 'rut5_v3', exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb29b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8439903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7267/7267 [42:13<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 2.220028813815074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 853/853 [00:17<00:00, 48.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, eval_loss: 4.255956073718502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7267/7267 [38:49<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 1.5575248665550938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 853/853 [00:17<00:00, 48.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, eval_loss: 4.377725107099638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7267/7267 [38:50<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss: 1.2455130992097148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 853/853 [00:17<00:00, 48.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, eval_loss: 4.151368267091748\n"
     ]
    }
   ],
   "source": [
    "args = Params(3, 3, 5.74e-5, 0.238, 986, 12, 0.1)\n",
    "train_and_eval('rut5_v3', train_medium_pairs, eval_pairs, args, 'medium_mix', 'rut5_v4', exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5ea9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3a55abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46872/46872 [3:35:27<00:00,  3.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 2.2122508593979426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2560/2560 [00:35<00:00, 72.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, eval_loss: 2.0960394582652953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46872/46872 [3:21:49<00:00,  3.87it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 1.7540695584304586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2560/2560 [00:35<00:00, 72.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, eval_loss: 2.2730193296447396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46872/46872 [3:21:31<00:00,  3.88it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss: 1.5614262155601624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2560/2560 [00:34<00:00, 73.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, eval_loss: 2.3550713327247648\n"
     ]
    }
   ],
   "source": [
    "args = Params(1, 3, 5.74e-5, 0.238, 986, 12, 0.1)\n",
    "train_and_eval('rut5_v4', train_large_pairs, eval_pairs, args, 'large_mix', 'rut5_v5', exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87118e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd95ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118228/118228 [7:05:32<00:00,  4.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 2.0305616433466303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:16<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, eval_loss: 8.665217665999148\n"
     ]
    }
   ],
   "source": [
    "args = Params(6, 1, 5.74e-5, 0.238, 986, 12, 0.1)\n",
    "train_and_eval('rut5_v5', train_para_phraser_pairs, eval_pairs, args, 'para_phraser', 'rut5_v6', exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a5be6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22586/22586 [1:59:19<00:00,  3.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 1.6359715027598811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 853/853 [00:17<00:00, 48.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, eval_loss: 4.339362796138348\n"
     ]
    }
   ],
   "source": [
    "args = Params(3, 1, 2e-5, None, None, None, None)\n",
    "train_and_eval_base('rut5_v2', train_ext_pairs, eval_pairs, args, 'my_run', 'rut5_v7', exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3bc57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nkhozin\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 16719/16719 [1:14:11<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 1.9118042747118615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 853/853 [00:18<00:00, 45.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, eval_loss: 1.2105605122693328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16719/16719 [1:09:57<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 1.2695603867003948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 853/853 [00:19<00:00, 44.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, eval_loss: 0.9644441406383394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 9335/16719 [38:48<28:16,  4.35it/s]  "
     ]
    }
   ],
   "source": [
    "args = Params(3, 3, 2e-5, None, None, None, None)\n",
    "train_and_eval_base('cointegrated/rut5-base-multitask', train_clean_pairs, eval_pairs, args, 'clean_data_mix', 'rut5_v8', exp_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
